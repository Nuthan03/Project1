{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nuthan03/Project1/blob/main/Project1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLTka2Ni2S38"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()\n",
        "print(digits.data.shape)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.gray()\n",
        "plt.matshow(digits.images[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UMmiW5h2kfM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import balanced_accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4I1nfU2K3DZ7"
      },
      "outputs": [],
      "source": [
        "digits = load_digits()\n",
        "print(digits.data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMR3_Qji3Fea"
      },
      "outputs": [],
      "source": [
        "digits = load_digits()\n",
        "print(digits.data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcbiEByU__1v"
      },
      "outputs": [],
      "source": [
        "# Dictionary to store trained models\n",
        "models = {}\n",
        "tunned_models = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duXRxyCc3Q68"
      },
      "outputs": [],
      "source": [
        "plt.gray()\n",
        "plt.matshow(digits.images[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pl9AbUJc3U77"
      },
      "outputs": [],
      "source": [
        "X = digits.data\n",
        "y = digits.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9lX8pWJ7AXP"
      },
      "source": [
        "1.Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEIW4Bx13i15"
      },
      "outputs": [],
      "source": [
        "model1 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model1.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOv6pjEv3rTZ"
      },
      "outputs": [],
      "source": [
        "y_pred = model1.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "print(f\"Balanced Accuracy Score: {balanced_acc:.4f}\")\n",
        "\n",
        "models[\"Random Forest\"] = model1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id8HX6xM8xI1"
      },
      "source": [
        "Hyper Tunning Random Forest with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnoW7rbf8wia"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrvWGUUB8BWJ"
      },
      "outputs": [],
      "source": [
        "model2 = RandomForestClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(estimator=model2, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49WOMjfq8BJg"
      },
      "outputs": [],
      "source": [
        "grid_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkZyEqmA8A-i"
      },
      "outputs": [],
      "source": [
        "print(\"Best parameters found: \", grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNrw4oQ48Axc"
      },
      "outputs": [],
      "source": [
        "best_model1 = grid_search.best_estimator_\n",
        "y_pred = best_model1.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "print(f\"Balanced Accuracy Score: {balanced_acc:.4f}\")\n",
        "\n",
        "#models[\"Tunned Random Forest\"] = best_model1\n",
        "tunned_models[\"Tunned Random Forest\"] = best_model1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlkMJNgy66un"
      },
      "source": [
        "2.SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svMPfjGj3vgy"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdeFlTSe4UzS"
      },
      "outputs": [],
      "source": [
        "Model3 = SVC(random_state=42)\n",
        "Model3.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPBmpIq1507a"
      },
      "outputs": [],
      "source": [
        "y_pred = Model3.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "print(f\"Balanced Accuracy Score: {balanced_acc:.4f}\")\n",
        "\n",
        "models[\"SVM\"] = Model3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLyMktgV_taq"
      },
      "source": [
        "Hyper Tunning SVM with RandomizedSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTzuN6SM_s4x"
      },
      "outputs": [],
      "source": [
        "param_dist = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': [1, 0.1, 0.01, 0.001],\n",
        "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VX7vWqcz_soK"
      },
      "outputs": [],
      "source": [
        "Model4 = SVC(random_state=42)\n",
        "random_search = RandomizedSearchCV(estimator=Model4, param_distributions=param_dist, n_iter=100, cv=5, n_jobs=-1, verbose=2, scoring='accuracy', random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFEIIo-P_sgq"
      },
      "outputs": [],
      "source": [
        "random_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPzs0EPP_sZD"
      },
      "outputs": [],
      "source": [
        "print(\"Best parameters found: \", random_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZElP5FE_sRX"
      },
      "outputs": [],
      "source": [
        "best_model2 = random_search.best_estimator_\n",
        "y_pred = best_model2.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "print(f\"Balanced Accuracy Score: {balanced_acc:.4f}\")\n",
        "\n",
        "#models[\"Tunned SVM\"] = best_model2\n",
        "tunned_models[\"Tunned SVM\"] = best_model2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm62axCo6lO1"
      },
      "source": [
        "3.Knn Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-ZwqdAn524S"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlIUgiOK6WEb"
      },
      "outputs": [],
      "source": [
        "Model5 = KNeighborsClassifier(n_neighbors=5)\n",
        "Model5.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFCes5Bu6arS"
      },
      "outputs": [],
      "source": [
        "y_pred = Model5.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "print(f\"Balanced Accuracy Score: {balanced_acc:.4f}\")\n",
        "\n",
        "models[\"KNN\"] = Model5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CXB8ZqHJac0"
      },
      "source": [
        "Hyper Tunning KNN with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwAnBXMYJZab"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dnfmi9TJYxU"
      },
      "outputs": [],
      "source": [
        "Model6 = KNeighborsClassifier()\n",
        "grid_search = GridSearchCV(estimator=Model6, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cy2qzpNNJYgI"
      },
      "outputs": [],
      "source": [
        "grid_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sla-KLT5JYRT"
      },
      "outputs": [],
      "source": [
        "print(\"Best parameters found: \", grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpW2WClvKsON"
      },
      "outputs": [],
      "source": [
        "best_model3 = grid_search.best_estimator_\n",
        "y_pred = best_model3.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "print(f\"Balanced Accuracy Score: {balanced_acc:.4f}\")\n",
        "\n",
        "#models[\"Tunned KNN\"] = best_model3\n",
        "tunned_models[\"Tunned KNN\"] = best_model3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Scc10gJR7ZJS"
      },
      "source": [
        "4.AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6rrOU0P6evC"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Cf8Nkyi73Mi"
      },
      "outputs": [],
      "source": [
        "Model7 = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "Model7.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFcE7DA375Zy"
      },
      "outputs": [],
      "source": [
        "y_pred = Model7.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "print(f\"Balanced Accuracy Score: {balanced_acc:.4f}\")\n",
        "\n",
        "models[\"AdaBoost\"] = Model7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_3CUhRSPL0A"
      },
      "source": [
        "HyperTunning AdaBoost with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6G3f0b_sNU73"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 1.0],\n",
        "    'algorithm': ['SAMME', 'SAMME.R']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biQdvVEDNUtM"
      },
      "outputs": [],
      "source": [
        "Model8 = AdaBoostClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(estimator=Model8, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxqgHX58NUph"
      },
      "outputs": [],
      "source": [
        "grid_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDPvqGSyNUmg"
      },
      "outputs": [],
      "source": [
        "print(\"Best parameters found: \", grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEdSBM2nPgI3"
      },
      "outputs": [],
      "source": [
        "best_model4 = grid_search.best_estimator_\n",
        "y_pred = best_model4.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "print(f\"Balanced Accuracy Score: {balanced_acc:.4f}\")\n",
        "\n",
        "#models[\"Tunned AdaBoost\"] = best_model4\n",
        "tunned_models[\"Tunned AdaBoost\"] = best_model4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8XpEzoi8LGe"
      },
      "source": [
        "5.GradientBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8OxVptH7756"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier # Import GradientBoostingClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEW8Np4C8B9y"
      },
      "outputs": [],
      "source": [
        "#Model9 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "#Model9.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LOlxjrQ__2g"
      },
      "outputs": [],
      "source": [
        "\n",
        "Model9 = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "Model9.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoipAL8Z8D9a"
      },
      "outputs": [],
      "source": [
        "y_pred = Model9.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "print(f\"Balanced Accuracy Score: {balanced_acc:.4f}\")\n",
        "\n",
        "models[\"Gradient Boost\"] = Model9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnvDuaa9R0AW"
      },
      "source": [
        "Hypertunning GradientBoost with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_ka_tmHRzvb"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aiuvm-3_Rzgg"
      },
      "outputs": [],
      "source": [
        "Model10 = GradientBoostingClassifier(random_state=42)\n",
        "random_search = RandomizedSearchCV(estimator=Model10, param_distributions=param_grid,\n",
        "                                   n_iter=10, cv=5, n_jobs=-1, verbose=2,\n",
        "                                   scoring='balanced_accuracy', random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzlszLL7RzdF"
      },
      "outputs": [],
      "source": [
        "random_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOwGBWZfRzaI"
      },
      "outputs": [],
      "source": [
        "print(\"Best parameters found: \", random_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsSmxyzYRzXV"
      },
      "outputs": [],
      "source": [
        "best_model5 = random_search.best_estimator_\n",
        "y_pred = best_model5.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "print(f\"Balanced Accuracy Score: {balanced_acc:.4f}\")\n",
        "\n",
        "#models[\"Tuned Gradient Boosting\"] = best_model5\n",
        "tunned_models[\"Tunned Gradient Boosting\"] = best_model5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3S5ftqj8xIB"
      },
      "source": [
        "6.Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eM3ADEzA8uoI"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5L9FrLO98ulZ"
      },
      "outputs": [],
      "source": [
        "Model11 = LogisticRegression(random_state=42, max_iter=1000)\n",
        "Model11.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmTDSXpC8uiv"
      },
      "outputs": [],
      "source": [
        "y_pred = Model11.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "print(f\"Balanced Accuracy Score: {balanced_acc:.4f}\")\n",
        "\n",
        "models[\"Logistic Regression\"] = Model11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o9mZG47o8Pw"
      },
      "source": [
        "Hypertunning Logistic Regression with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CXUrAhZo3pZ"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
        "    'penalty': ['l2'],\n",
        "    'max_iter': [100, 200, 500, 1000]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPuBuPTto3aQ"
      },
      "outputs": [],
      "source": [
        "Model12 = LogisticRegression(random_state=42)\n",
        "grid_search = GridSearchCV(estimator=Model12, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BW0EH-qJo3Oh"
      },
      "outputs": [],
      "source": [
        "grid_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZv12dIZo3CH"
      },
      "outputs": [],
      "source": [
        "print(\"Best parameters found: \", grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "focEXxq6o2zO"
      },
      "outputs": [],
      "source": [
        "best_model6 = grid_search.best_estimator_\n",
        "y_pred = best_model6.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "print(f\"Balanced Accuracy Score: {balanced_acc:.4f}\")\n",
        "\n",
        "#models[\"Tunned Logistic Regression\"] = best_model6\n",
        "tunned_models[\"Tunned Logistic Regression\"] = best_model6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yvhPuo6__2o"
      },
      "source": [
        "7. Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7ewbFFf__2p"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "\n",
        "# Initial Decision Tree Model\n",
        "Model13 = DecisionTreeClassifier(random_state=42)\n",
        "Model13.fit(X_train, y_train)\n",
        "\n",
        "y_pred = Model13.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "print(f\"Balanced Accuracy Score: {balanced_acc:.4f}\")\n",
        "\n",
        "models[\"Decision Tree\"] = Model13"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5CMqILM__2p"
      },
      "source": [
        "Hypertunning Decision Tree with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tagZ9kTG__2q"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 10, 20, 30, 50],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "Model14 = DecisionTreeClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(estimator=Model14, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "\n",
        "best_model7 = grid_search.best_estimator_\n",
        "y_pred = best_model7.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "print(f\"Balanced Accuracy Score: {balanced_acc:.4f}\")\n",
        "\n",
        "#models[\"Tuned Decision Tree\"] = best_model7\n",
        "tunned_models[\"Tunned Decision Tree\"] = best_model7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR79_9yh__2q"
      },
      "source": [
        "8. Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFcOo_O4__2r"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "\n",
        "# Initial Naïve Bayes Model\n",
        "Model15 = GaussianNB()\n",
        "Model15.fit(X_train, y_train)\n",
        "\n",
        "y_pred = Model15.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "print(f\"Balanced Accuracy Score: {balanced_acc:.4f}\")\n",
        "\n",
        "models[\"Naive Bayes\"] = Model15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srZd1Hkr__2s"
      },
      "source": [
        "Hypertunning Naive Bayes with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o049nuut__2s"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3]\n",
        "}\n",
        "\n",
        "Model16 = GaussianNB()\n",
        "grid_search = GridSearchCV(estimator=Model16, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='balanced_accuracy')\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "\n",
        "best_model8 = grid_search.best_estimator_\n",
        "y_pred = best_model8.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "print(f\"Balanced Accuracy Score: {balanced_acc:.4f}\")\n",
        "\n",
        "#models[\"Tuned Naïve Bayes\"] = best_model8\n",
        "tunned_models[\"Tunned Naïve Bayes\"] = best_model8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNqveKMj__2t"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Function to plot confusion matrix\n",
        "def plot_confusion_matrix(model_name, y_test, y_pred, class_labels):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_labels, yticklabels=class_labels)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
        "    plt.show()\n",
        "\n",
        "# Iterate over models dictionary and plot confusion matrices\n",
        "class_labels = sorted(set(y_test))  # Get unique class labels from y_test\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    y_pred = model.predict(X_test)  # Predict using the model\n",
        "    plot_confusion_matrix(model_name, y_test, y_pred, class_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9187UpB__2u"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrices(models, tunned_models, X_test, y_test, class_labels):\n",
        "\n",
        "    plt.figure(figsize=(12, len(models) * 5))\n",
        "\n",
        "    for idx, (model_name, model) in enumerate(models.items()):\n",
        "\n",
        "        tunned_model_name = list(tunned_models.keys())[idx]\n",
        "        tunned_model = tunned_models[tunned_model_name]\n",
        "\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "        y_pred = model.predict(X_test)\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=class_labels, yticklabels=class_labels, ax=axes[0])\n",
        "        axes[0].set_xlabel(\"Predicted\")\n",
        "        axes[0].set_ylabel(\"Actual\")\n",
        "        axes[0].set_title(f\"Confusion Matrix - {model_name}\")\n",
        "\n",
        "        y_pred_tunned = tunned_model.predict(X_test)\n",
        "        cm_tunned = confusion_matrix(y_test, y_pred_tunned)\n",
        "        sns.heatmap(cm_tunned, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=class_labels, yticklabels=class_labels, ax=axes[1])\n",
        "        axes[1].set_xlabel(\"Predicted\")\n",
        "        axes[1].set_ylabel(\"Actual\")\n",
        "        axes[1].set_title(f\"Confusion Matrix - {tunned_model_name}\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmLO7RPl__2v"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrices(models, tunned_models, X_test, y_test, class_labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_0koytk__2w"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_macro_avg_roc(models, X_test, y_test, class_labels):\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    y_test_binarized = label_binarize(y_test, classes=class_labels)\n",
        "    n_classes = len(class_labels)\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        try:\n",
        "\n",
        "            y_score = model.predict_proba(X_test)\n",
        "\n",
        "            fpr = dict()\n",
        "            tpr = dict()\n",
        "            roc_auc = dict()\n",
        "\n",
        "            for i in range(n_classes):\n",
        "                fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_score[:, i])\n",
        "                roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "            all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "            mean_tpr = np.zeros_like(all_fpr)\n",
        "\n",
        "            for i in range(n_classes):\n",
        "                mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "            mean_tpr /= n_classes\n",
        "            macro_auc = auc(all_fpr, mean_tpr)\n",
        "\n",
        "            plt.plot(all_fpr, mean_tpr, label=f\"{model_name} (AUC = {macro_auc:.2f})\")\n",
        "\n",
        "        except AttributeError:\n",
        "            print(f\"Model '{model_name}' does not support probability prediction.\")\n",
        "\n",
        "    # Plot random classifier line\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label=\"Random Classifier (AUC = 0.50)\")\n",
        "\n",
        "\n",
        "    plt.xlim(0.0, 1.0)\n",
        "    plt.ylim(0.9, 1.001)\n",
        "\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"Zoomed-In Macro-Averaged ROC Curves for All Models\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fO3EBxH__2x"
      },
      "outputs": [],
      "source": [
        "\n",
        "plot_macro_avg_roc(models, X_test, y_test, class_labels)\n",
        "plot_macro_avg_roc(tunned_models, X_test, y_test, class_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tR0KVN6Q__2y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXE91WAq__2y"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import numpy as np\n",
        "\n",
        "def calculate_macro_avg_roc_auc(models, X_test, y_test, class_labels):\n",
        "\n",
        "    y_test_binarized = label_binarize(y_test, classes=class_labels)\n",
        "    n_classes = len(class_labels)\n",
        "\n",
        "    auc_scores = {}\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        try:\n",
        "            y_score = model.predict_proba(X_test)\n",
        "\n",
        "            macro_auc = roc_auc_score(y_test_binarized, y_score, average=\"macro\", multi_class=\"ovr\")\n",
        "\n",
        "            auc_scores[model_name] = macro_auc\n",
        "            print(f\"{model_name}: Macro-Averaged ROC AUC = {macro_auc:.4f}\")\n",
        "\n",
        "        except AttributeError:\n",
        "            print(f\"Model '{model_name}' does not support probability prediction.\")\n",
        "\n",
        "    return auc_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnUMcRZk__2z"
      },
      "outputs": [],
      "source": [
        "macro_auc_scores = calculate_macro_avg_roc_auc(models, X_test, y_test, class_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBrjGoN1dV29"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "digits = load_digits()\n",
        "X = digits.data\n",
        "y = digits.target\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "pca = PCA(n_components=0.95)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "Model3 = SVC(random_state=42)\n",
        "Model3.fit(X_pca, y_train)\n",
        "y_pred = Model3.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "print(f\"Balanced Accuracy Score: {balanced_acc:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Number of PCA components selected: {X_pca.shape[1]}\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o', linestyle='--')\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.title('Explained Variance by PCA Components')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdx993ae__20"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "digits = load_digits()\n",
        "X = digits.data\n",
        "y = digits.target\n",
        "\n",
        "# Split the dataset before applying PCA (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)  # Use the same scaler\n",
        "\n",
        "# Apply PCA (fit only on training data)\n",
        "pca = PCA(n_components=0.95)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)  # Apply the same transformation\n",
        "\n",
        "# Train SVM model\n",
        "model = SVC(random_state=42)\n",
        "model.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test_pca)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(f\"Balanced Accuracy Score: {balanced_acc:.4f}\")\n",
        "print(f\"Number of PCA components selected: {X_train_pca.shape[1]}\")\n",
        "\n",
        "# Plot explained variance\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o', linestyle='--')\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.title('Explained Variance by PCA Components')\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}